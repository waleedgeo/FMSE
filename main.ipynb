{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading modules\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# initialize ee \n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1: Pakistan Floods 2022\n",
    "# inputs\n",
    "# Define the Area of Interest (aoi)\n",
    "\n",
    "name = 'Pakistan_Floods_2022'\n",
    "aoi = ee.Geometry.Polygon(\n",
    "    [[[67.98392410136336, 26.049909335428502],\n",
    "      [67.98392410136336, 25.42892423506662],\n",
    "      [68.59778518534773, 25.42892423506662],\n",
    "      [68.59778518534773, 26.049909335428502]]])\n",
    "\n",
    "startDate = ee.Date('2022-03-01')\n",
    "endDate = ee.Date('2022-08-20')\n",
    "predays = 60\n",
    "postdays = 20\n",
    "\n",
    "# optional\n",
    "zvv_value = -3\n",
    "zvh_val = -3\n",
    "water_value = 75\n",
    "elev_value = 800\n",
    "slope_value = 10\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangkok', 'Jakarta', 'Manila', 'Hochiminh', 'Mumbai']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ee.FeatureCollection(\"projects/temporaryproj/assets/fs_cities_boundary_combined\")\n",
    "# print all names of features with property name\n",
    "a.aggregate_array('name').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cities Info\n",
    "name = 'Mumbai'\n",
    "startDate = ee.Date('2017-03-01')\n",
    "endDate = ee.Date('2017-08-22')\n",
    "predays = 30\n",
    "postdays = 10\n",
    "\n",
    "\n",
    "name = 'Bangkok'\n",
    "startDate = ee.Date('2023-01-01')\n",
    "endDate = ee.Date('2023-09-25')\n",
    "predays = 60\n",
    "postdays = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 2: Mumbai\n",
    "# inputs\n",
    "# Define the Area of Interest (aoi)\n",
    "name = 'Bangkok'\n",
    "startDate = ee.Date('2023-01-01')\n",
    "endDate = ee.Date('2023-09-25')\n",
    "predays = 60\n",
    "postdays = 10\n",
    "\n",
    "fsm_cities_box = ee.FeatureCollection(\"projects/temporaryproj/assets/fs_cities_boundarybox_combined\")\n",
    "aoi = fsm_cities_box.filter(ee.Filter.eq('name', f'{name}_aoi')).geometry()\n",
    "fsm_cities = ee.FeatureCollection(\"projects/temporaryproj/assets/fs_cities_boundary_combined\")\n",
    "aoi_city = fsm_cities.filter(ee.Filter.eq('name', name)).geometry()\n",
    "\n",
    "zvv_value = -3\n",
    "zvh_val = -3\n",
    "water_value = 75\n",
    "elev_value = 800\n",
    "slope_value = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s1_col(date, days):\n",
    "  filters = [\n",
    "    ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VV\"),\n",
    "    ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VH\"),\n",
    "    ee.Filter.Or(ee.Filter.equals(\"instrumentMode\", \"IW\"),ee.Filter.equals(\"instrumentMode\", \"SM\")),\n",
    "    ee.Filter.bounds(aoi),\n",
    "    ee.Filter.eq('resolution_meters', 10),\n",
    "    ee.Filter.date(date, date.advance(days+1, 'day'))\n",
    "  ]\n",
    "  \n",
    "  s1_col = ee.ImageCollection('COPERNICUS/S1_GRD').filter(filters)\n",
    "\n",
    "  return s1_col\n",
    "\n",
    "\n",
    "s1_pre = get_s1_col(startDate, predays).select(['VV', 'VH'])\n",
    "s1_post = get_s1_col(endDate, postdays).select(['VV', 'VH'])\n",
    "\n",
    "# images in s1 pre and post\n",
    "print('Images in S1 Pre: ',s1_pre.size().getInfo())\n",
    "print('Images in S1 Post: ',s1_post.size().getInfo())\n",
    "\n",
    "asc = ee.Filter.eq(\"orbitProperties_pass\", \"ASCENDING\")\n",
    "des = ee.Filter.eq(\"orbitProperties_pass\", \"DESCENDING\")\n",
    "\n",
    "# Function to calculate z-score\n",
    "def calc_zscore(s1_pre, s1_post, direction):\n",
    "    base_mean = s1_pre.filter(ee.Filter.equals('orbitProperties_pass', direction)).mean()\n",
    "\n",
    "    anom = s1_post.filter(ee.Filter.equals('orbitProperties_pass', direction)) \\\n",
    "        .mean().subtract(base_mean).set({'system:time_start': s1_post.get('system:time_start')})\n",
    "\n",
    "    base_sd = s1_pre.filter(ee.Filter.equals('orbitProperties_pass', direction)) \\\n",
    "        .reduce(ee.Reducer.stdDev()).rename(['VV', 'VH'])\n",
    "\n",
    "    return anom.divide(base_sd).set({'system:time_start': anom.get('system:time_start')})\n",
    "\n",
    "def zscore_combined():\n",
    "  zscore_des = calc_zscore(s1_pre, s1_post,'DESCENDING')\n",
    "  zscore_asc = calc_zscore(s1_pre, s1_post,'ASCENDING')\n",
    "\n",
    "  # Calculate mean of z-scores for DESCENDING and ASCENDING orbits\n",
    "  zscore = ee.ImageCollection.fromImages([zscore_des, zscore_asc]).mean().clip(aoi)\n",
    "\n",
    "  return zscore\n",
    "\n",
    "# caculate zscore for only ascending orbits\n",
    "def zscore_asc():\n",
    "  base_mean = s1_pre.filter(asc).mean()\n",
    "  anom = s1_post.filter(asc)\\\n",
    "                .mean().subtract(base_mean)\n",
    "  base_sd = s1_pre.filter(asc)\\\n",
    "                .reduce(ee.Reducer.stdDev()).rename(['VV', 'VH'])\n",
    "  zscore = anom.divide(base_sd)\n",
    "  return zscore\n",
    "\n",
    "# caculate zscore for only descending orbits\n",
    "def zscore_des():\n",
    "  base_mean = s1_pre.filter(des).mean()\n",
    "  anom = s1_post.filter(des)\\\n",
    "                .mean().subtract(base_mean)\n",
    "  base_sd = s1_pre.filter(des)\\\n",
    "                .reduce(ee.Reducer.stdDev()).rename(['VV', 'VH'])\n",
    "  zscore = anom.divide(base_sd)\n",
    "  return zscore\n",
    "\n",
    "def zscore_cond():\n",
    "  cond_a = s1_pre.filter(ee.Filter.eq(\"orbitProperties_pass\", \"ASCENDING\")).size().gt(0)\n",
    "  cond_b = s1_pre.filter(ee.Filter.eq(\"orbitProperties_pass\", \"DESCENDING\")).size().gt(0)\n",
    "  cond_c = s1_post.filter(ee.Filter.eq(\"orbitProperties_pass\", \"ASCENDING\")).size().gt(0)\n",
    "  cond_d = s1_post.filter(ee.Filter.eq(\"orbitProperties_pass\", \"DESCENDING\")).size().gt(0)\n",
    "  \n",
    "  cond_asc = cond_a.And(cond_c)\n",
    "  cond_des = cond_b.And(cond_d)\n",
    "  if cond_asc == 1:\n",
    "    images = zscore_asc()\n",
    "    zscore = ee.ImageCollection.fromImages([images]).mean().clip(aoi)\n",
    "  else:\n",
    "    images = zscore_des()\n",
    "    zscore = ee.ImageCollection.fromImages([images]).mean().clip(aoi)\n",
    "  \n",
    "  return zscore\n",
    "\n",
    "# Check if both ascending and descending collections are empty\n",
    "pre_hasAscending = s1_pre.filter([asc]).size().gt(0)\n",
    "pre_hasDescending = s1_pre.filter([des]).size().gt(0)\n",
    "post_hasAscending = s1_post.filter([asc]).size().gt(0)\n",
    "post_hasDescending = s1_post.filter([des]).size().gt(0)\n",
    "\n",
    "cond = pre_hasAscending.And(pre_hasDescending).And(post_hasAscending).And(post_hasDescending)\n",
    "\n",
    "if cond == 1:\n",
    "  zscore = zscore_combined()\n",
    "else:\n",
    "  zscore = zscore_cond()\n",
    "\n",
    "\n",
    "# Flood mask function\n",
    "def mapFloods(z, zvv_thd=zvv_value, zvh_thd=zvh_val, pow_thd=water_value, elev_thd=elev_value, slp_thd=slope_value):\n",
    "\n",
    "    # JRC water mask\n",
    "    jrc = ee.ImageCollection(\"JRC/GSW1_1/MonthlyHistory\").filterDate('2016-01-01', '2022-01-01')\n",
    "    jrcvalid = jrc.map(lambda x: x.gt(0)).sum()\n",
    "    jrcwat = jrc.map(lambda x: x.eq(2)).sum().divide(jrcvalid).multiply(100)\n",
    "    jrcmask = jrcvalid.gt(0)\n",
    "    ow = jrcwat.gte(ee.Image(pow_thd))\n",
    "\n",
    "    # Add elevation and slope masking using fabdem\n",
    "    elevation = ee.ImageCollection(\"projects/sat-io/open-datasets/FABDEM\").mosaic() \\\n",
    "        .setDefaultProjection('EPSG:3857', None, 30)\n",
    "    slope = ee.Terrain.slope(elevation)\n",
    "\n",
    "    # Classify floods\n",
    "    vvflag = z.select('VV').lte(ee.Image(zvv_thd))\n",
    "    vhflag = z.select('VH').lte(ee.Image(zvh_thd))\n",
    "\n",
    "    flood_class = ee.Image(0).add(vvflag) \\\n",
    "        .add(vhflag.multiply(2)) \\\n",
    "        .where(ow.eq(1), 4) \\\n",
    "        .rename('flood_class') \\\n",
    "        .where(elevation.gt(elev_thd).multiply(ow.neq(1)), 0) \\\n",
    "        .where(slope.gt(slp_thd).multiply(ow.neq(1)), 0)\n",
    "    # add class 1,2,3 from flood_class and create a new layer with single band\n",
    "    flood_layer = flood_class.where(flood_class.eq(1), 1) \\\n",
    "        .where(flood_class.eq(2), 1) \\\n",
    "        .where(flood_class.eq(3), 1) \\\n",
    "        .where(flood_class.eq(4), 2) \\\n",
    "        .where(jrcmask.eq(0), 2) \\\n",
    "        .where(flood_class.eq(0), 2) \\\n",
    "        .selfMask() \\\n",
    "        .rename('label')\n",
    "    return flood_class.clip(aoi), flood_layer.clip(aoi)\n",
    "\n",
    "# Mask z-score threshold\n",
    "flood_class, flood_layer = mapFloods(zscore)\n",
    "\n",
    "# sampling\n",
    "\n",
    "\n",
    "# Create the 'sample' feature collection\n",
    "\n",
    "\n",
    "sample = flood_layer.stratifiedSample(\n",
    "    numPoints=num_samples,\n",
    "    classBand='label',\n",
    "    region=aoi,\n",
    "    scale=10,\n",
    "    seed=5,\n",
    "    tileScale=1.5,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "# initially non flood is labeled 2, we will now change 2 to 0\n",
    "def updateFeature(feature):\n",
    "    value = feature.get('label')\n",
    "    cond = ee.Algorithms.IsEqual(value, ee.Number(2))\n",
    "    updated_value = ee.Algorithms.If(cond, ee.Number(0), value)\n",
    "    feature = feature.set('label', updated_value)\n",
    "    return feature\n",
    "label = sample.map(updateFeature)\n",
    "\n",
    "\n",
    "\n",
    "# inputs in classificaation\n",
    "\n",
    "image = s1_post.mean().clip(aoi)\n",
    "bands = ['VV', 'VH']\n",
    "\n",
    "\n",
    "# training\n",
    "sample_all = image.select(bands).sampleRegions(**{\n",
    "    'collection': label,\n",
    "    'properties': ['label'],\n",
    "    'scale': 10\n",
    "})\n",
    "\n",
    "sample_all = sample_all.randomColumn()\n",
    "\n",
    "split = 0.9\n",
    "training = sample_all.filter(ee.Filter.lt('random', split))\n",
    "validation = sample_all.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "\n",
    "classifier = ee.Classifier.smileRandomForest(115).train(**{\n",
    "    'features': training,\n",
    "    'classProperty': 'label',\n",
    "    'inputProperties': bands\n",
    "})\n",
    "results = image.select(bands).classify(classifier)\n",
    "\n",
    "sample_sus = results.stratifiedSample(\n",
    "    numPoints=num_samples,\n",
    "    classBand='label',\n",
    "    region=aoi,\n",
    "    scale=10,\n",
    "    seed=5,\n",
    "    tileScale=1.5,\n",
    "    geometries=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Susceptibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables Preperation for Susceptibility\n",
    "\n",
    "\n",
    "# varianles used DEM, Slope, Aspect, NDVI, NDWI, NDBI, NDSI\n",
    "\n",
    "# Applies scaling factors.\n",
    "year = endDate.get('year')\n",
    "def applyScaleFactors(image):\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "    \n",
    "    return image.addBands(opticalBands, None, True)\\\n",
    "              .addBands(thermalBands, None, True)\n",
    "\n",
    "def remapper(image):\n",
    "        remapped = image.remap([1,2,4,5,7,8,9,10,11],[1,2,3,4,5,6,7,8,9])\n",
    "        return remapped\n",
    "\n",
    "# datasets\n",
    "dem = ee.ImageCollection(\"projects/sat-io/open-datasets/FABDEM\")\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .mosaic()\\\n",
    "        .clip(aoi)\n",
    "\n",
    "slope = ee.Terrain.slope(dem)\n",
    "aspect = ee.Terrain.aspect(dem)\n",
    "\n",
    "\n",
    "l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .filter(ee.Filter.calendarRange(year, year, 'year'))\\\n",
    "        .map(applyScaleFactors)\\\n",
    "        .filter(ee.Filter.lt('CLOUD_COVER', 10))\\\n",
    "        .median()\\\n",
    "        .clip(aoi)\n",
    "\n",
    "\n",
    "ndvi = l9.normalizedDifference(['SR_B5', 'SR_B4'])\n",
    "ndwi = l9.normalizedDifference(['SR_B3', 'SR_B5'])\n",
    "ndbi = l9.normalizedDifference(['SR_B6', 'SR_B5'])\n",
    "ndsi = l9.normalizedDifference(['SR_B2', 'SR_B5'])\n",
    "\n",
    "l9 = l9.select(['SR_B1','SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n",
    "\n",
    "image_sus = l9.addBands(dem).addBands(slope).addBands(aspect).addBands(ndvi).addBands(ndwi).addBands(ndbi).addBands(ndsi).clip(aoi)\n",
    "\n",
    "bands_sus = image_sus.bandNames().getInfo()\n",
    "\n",
    "# training\n",
    "sample_all_sus = image_sus.select(bands_sus).sampleRegions(**{\n",
    "    'collection': label,\n",
    "    'properties': ['label'],\n",
    "    'scale': 30\n",
    "})\n",
    "\n",
    "sample_all_sus = sample_all_sus.randomColumn()\n",
    "\n",
    "split = 0.9\n",
    "training_sus = sample_all_sus.filter(ee.Filter.lt('random', split))\n",
    "validation_sus = sample_all_sus.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "\n",
    "classifier_sus = ee.Classifier.smileRandomForest(115).train(**{\n",
    "    'features': training_sus,\n",
    "    'classProperty': 'label',\n",
    "    'inputProperties': bands_sus\n",
    "})\n",
    "\n",
    "classifier_prob = classifier_sus.setOutputMode('PROBABILITY')\n",
    "results_prob = image_sus.select(bands).classify(classifier_prob)\n",
    "\n",
    "Map.addLayer(results_prob, {'min': 0, 'max': 1, 'palette': ['green', 'blue', 'red']}, 'Flood Susceptibility');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(results, {'min': 1, 'max': 3, 'palette': ['white', 'red', '233CF0']}, 'Flood Classified');\n",
    "Map.addLayer(results_prob, {'min': 0, 'max': 1, 'palette': ['white', 'blue', '233CF0']}, 'Flood Susceptibility');\n",
    "\n",
    "# map\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi)\n",
    "Map.addLayer(aoi, {}, 'Area of Interest')\n",
    "Map.addLayer(zscore.select('VV'), {'min': -7, 'max': 7, 'palette': ['red', 'white', 'blue']}, 'ZScore', False)\n",
    "Map.addLayer(flood_class, {'min': 0, 'max': 4, 'palette': ['#E3E3E3','#FFB100', '#FFB100', '#3E9DFF','#031DC9']}, 'flood classes', False)\n",
    "Map.addLayer(flood_layer, {'min': 1, 'max': 2, 'palette': ['blue', 'white']}, 'flood layer', False)\n",
    "Map.addLayer(label, {}, 'Label')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importance:  {'type': 'Feature', 'geometry': None, 'properties': {'VH': 2103.865866514957, 'VV': 2078.6021142779514}}\n",
      "Train Accuracy [[687, 8], [6, 678]]\n",
      "Overall Accuracy:  0.9898477157360406\n",
      "Kappa:  0.9796946092795193\n",
      "Producer Accuracy:  [[0.9884892086330935], [0.9912280701754386]]\n",
      "Consumer Accuracy:  [[0.9913419913419913, 0.9883381924198251]]\n",
      "Validation {'type': 'Feature', 'geometry': None, 'id': '1_0', 'properties': {'VH': -18.27881045056565, 'VV': -8.568157684616803, 'classification': 1, 'label': 1, 'random': 0.7433594988094623}}\n",
      "Validation Accuracy [[200, 105], [119, 197]]\n",
      "Validation Overall Accuracy:  0.6392914653784219\n",
      "Validation Kappa:  0.27893258135749593\n",
      "Validation Producer Accuracy:  [[0.6557377049180327], [0.6234177215189873]]\n",
      "Validation Consumer Accuracy:  [[0.6269592476489029, 0.652317880794702]]\n"
     ]
    }
   ],
   "source": [
    "classifier_explain = classifier.explain()\n",
    "variable_importance = ee.Feature(None, ee.Dictionary(classifier_explain).get('importance'))\n",
    "#print('Classifier Explain: ', classifier_explain)\n",
    "print('Variable Importance: ', variable_importance.getInfo())\n",
    "train_accuracy = classifier.confusionMatrix()\n",
    "print('Train Accuracy', train_accuracy.getInfo())\n",
    "print('Overall Accuracy: ', train_accuracy.accuracy().getInfo())\n",
    "print('Kappa: ', train_accuracy.kappa().getInfo())\n",
    "print('Producer Accuracy: ', train_accuracy.producersAccuracy().getInfo())\n",
    "print('Consumer Accuracy: ', train_accuracy.consumersAccuracy().getInfo())\n",
    "\n",
    "validated = validation.classify(classifier)\n",
    "print('Validation', validated.first().getInfo())\n",
    "test_accuracy = validated.errorMatrix('label', 'classification')\n",
    "print('Validation Accuracy', test_accuracy.getInfo())\n",
    "print('Validation Overall Accuracy: ', test_accuracy.accuracy().getInfo())\n",
    "print('Validation Kappa: ', test_accuracy.kappa().getInfo())\n",
    "print('Validation Producer Accuracy: ', test_accuracy.producersAccuracy().getInfo())\n",
    "print('Validation Consumer Accuracy: ', test_accuracy.consumersAccuracy().getInfo())\n",
    "\n",
    "f1_train = train_accuracy.fscore().getInfo()[1]\n",
    "print('F1 Score Train: ', f1_train)\n",
    "\n",
    "f1_test = test_accuracy.fscore().getInfo()[1]\n",
    "print('F1 Score Test: ', f1_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/tables/f75f23822f977346f5630f1fe8b1f716-47aa9b9af493b2e38ce0cc9dc6a1f3a6:getFeatures\n",
      "Please wait ...\n",
      "Data downloaded to e:\\current_proj\\FMS\\codes\\data\\Mumbai_label.shp\n"
     ]
    }
   ],
   "source": [
    "# exporting\n",
    "geemap.ee_to_shp(label, filename=f'../data/{name}_label.shp')\n",
    "#geemap.ee_export_image_to_drive(flood_layer, description='flood_layer', folder='s1_post', region=aoi, scale=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
