{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading modules\n",
    "import ee\n",
    "import geemap\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# initialize ee \n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7072752e06804ab386beadef0cc051b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=SearchDataGUI(childâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84b8131072f42cf95dd06f0342ccaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=None, description='Pre Date', step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488e044368fa444085406b83446124ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=None, description='Post Date', step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e31c7ad3e844b6788095c379b1618ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.9, description='Split Ratio', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9191048ef4be44679a5e19dd9446ad08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1000, description='Sample Size')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b29d93554104441a91913e5af8ad922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=1.0, description='Z-score Threshold')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedd82636cbf4f3884b2d29821d1fa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Export Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create widgets for input parameters\n",
    "aoi_widget = geemap.Map(center=(20, 0), zoom=2)\n",
    "aoi_widget.add_basemap('SATELLITE')\n",
    "aoi_widget.add_draw_control()\n",
    "\n",
    "pre_date_widget = widgets.DatePicker(description='Pre Date', disabled=False)\n",
    "post_date_widget = widgets.DatePicker(description='Post Date', disabled=False)\n",
    "split_widget = widgets.FloatSlider(value=0.9, min=0, max=1, step=0.01, description='Split Ratio')\n",
    "sample_size_widget = widgets.IntText(value=1000, description='Sample Size')\n",
    "zscore_threshold_widget = widgets.FloatText(value=1.0, description='Z-score Threshold')\n",
    "export_button = widgets.Button(description='Export Data', button_style='success')\n",
    "\n",
    "# Display the widgets\n",
    "display(aoi_widget)\n",
    "display(pre_date_widget, post_date_widget, split_widget, sample_size_widget, zscore_threshold_widget, export_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_s1_col(date, days):\n",
    "    filters = [\n",
    "        ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VV\"),\n",
    "        ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VH\"),\n",
    "        ee.Filter.Or(ee.Filter.equals(\"instrumentMode\", \"IW\"), ee.Filter.equals(\"instrumentMode\", \"SM\")),\n",
    "        ee.Filter.bounds(aoi),\n",
    "        ee.Filter.eq('resolution_meters', 10),\n",
    "        ee.Filter.date(date, date.advance(days + 1, 'day'))\n",
    "    ]\n",
    "    \n",
    "    s1_col = ee.ImageCollection('COPERNICUS/S1_GRD').filter(filters)\n",
    "    return s1_col\n",
    "\n",
    "def calc_zscore(s1_pre, s1_post, direction):\n",
    "    base_mean = s1_pre.filter(ee.Filter.equals('orbitProperties_pass', direction)).mean()\n",
    "    anom = s1_post.filter(ee.Filter.equals('orbitProperties_pass', direction)).mean().subtract(base_mean).set({'system:time_start': s1_post.get('system:time_start')})\n",
    "    base_sd = s1_pre.filter(ee.Filter.equals('orbitProperties_pass', direction)).reduce(ee.Reducer.stdDev()).rename(['VV', 'VH'])\n",
    "    return anom.divide(base_sd).set({'system:time_start': anom.get('system:time_start')})\n",
    "\n",
    "def zscore_combined(s1_pre, s1_post):\n",
    "    zscore_des = calc_zscore(s1_pre, s1_post, 'DESCENDING')\n",
    "    zscore_asc = calc_zscore(s1_pre, s1_post, 'ASCENDING')\n",
    "    zscore = ee.ImageCollection.fromImages([zscore_des, zscore_asc]).mean().clip(aoi)\n",
    "    return zscore\n",
    "\n",
    "def mapFloods(z, zvv_thd, zvh_thd, pow_thd, elev_thd, slp_thd):\n",
    "    jrc = ee.ImageCollection(\"JRC/GSW1_4/MonthlyHistory\").filterDate('2016-01-01', '2022-01-01')\n",
    "    jrcvalid = jrc.map(lambda x: x.gt(0)).sum()\n",
    "    jrcwat = jrc.map(lambda x: x.eq(2)).sum().divide(jrcvalid).multiply(100)\n",
    "    jrcmask = jrcvalid.gt(0)\n",
    "    ow = jrcwat.gte(ee.Image(pow_thd))\n",
    "\n",
    "    elevation = ee.ImageCollection(\"projects/sat-io/open-datasets/FABDEM\").mosaic().setDefaultProjection('EPSG:3857', None, 30)\n",
    "    slope = ee.Terrain.slope(elevation)\n",
    "\n",
    "    vvflag = z.select('VV').lte(ee.Image(zvv_thd))\n",
    "    vhflag = z.select('VH').lte(ee.Image(zvh_thd))\n",
    "\n",
    "    flood_class = ee.Image(0).add(vvflag).add(vhflag.multiply(2)).where(ow.eq(1), 4).rename('flood_class').where(elevation.gt(elev_thd).multiply(ow.neq(1)), 0).where(slope.gt(slp_thd).multiply(ow.neq(1)), 0)\n",
    "    flood_layer = flood_class.where(flood_class.eq(1), 1).where(flood_class.eq(2), 1).where(flood_class.eq(3), 1).where(flood_class.eq(4), 1).selfMask().rename('label')\n",
    "    return flood_class.clip(aoi), flood_layer.clip(aoi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_layers(aoi, pre_date, post_date, split_ratio, sample_size, zscore_threshold):\n",
    "    # Convert AOI to ee.Geometry\n",
    "    aoi_geometry = ee.Geometry.Polygon(aoi_widget.draw_last_feature.geometry()['coordinates'])\n",
    "\n",
    "    # Get Sentinel-1 collections\n",
    "    start_date = ee.Date(pre_date)\n",
    "    end_date = ee.Date(post_date)\n",
    "    s1_pre = get_s1_col(start_date, 15).select(['VV', 'VH'])\n",
    "    s1_post = get_s1_col(end_date, 15).select(['VV', 'VH'])\n",
    "\n",
    "    # Calculate z-score\n",
    "    zscore = zscore_combined(s1_pre, s1_post)\n",
    "\n",
    "    # Generate flood layer\n",
    "    flood_class, flood_layer = mapFloods(zscore, zvv_thd=zscore_threshold, zvh_thd=zscore_threshold, pow_thd=0.5, elev_thd=500, slp_thd=20)\n",
    "    \n",
    "    return flood_layer\n",
    "\n",
    "def on_export_button_clicked(b):\n",
    "    aoi = aoi_widget.draw_last_feature.geometry()['coordinates']\n",
    "    pre_date = pre_date_widget.value.strftime('%Y-%m-%d')\n",
    "    post_date = post_date_widget.value.strftime('%Y-%m-%d')\n",
    "    split_ratio = split_widget.value\n",
    "    sample_size = sample_size_widget.value\n",
    "    zscore_threshold = zscore_threshold_widget.value\n",
    "    \n",
    "    flood_layer = generate_layers(aoi, pre_date, post_date, split_ratio, sample_size, zscore_threshold)\n",
    "    \n",
    "    # Display results on the map\n",
    "    result_map = geemap.Map(center=(20, 0), zoom=2)\n",
    "    result_map.addLayer(flood_layer, {'min': 0, 'max': 1, 'palette': ['blue', 'red']}, 'Flood Layer')\n",
    "    result_map.add_basemap('SATELLITE')\n",
    "    display(result_map)\n",
    "    \n",
    "    # Export layers to Google Drive\n",
    "    export_flood_task = ee.batch.Export.image.toDrive(\n",
    "        image=flood_layer,\n",
    "        description='Flood_Mapping_Layer',\n",
    "        folder='earth_engine_exports',\n",
    "        scale=30,\n",
    "        region=aoi,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    export_flood_task.start()\n",
    "    \n",
    "    # Monitor export task progress\n",
    "    def monitor_tasks(tasks):\n",
    "        while any([task.status()['state'] in ['READY', 'RUNNING'] for task in tasks]):\n",
    "            for task in tasks:\n",
    "                status = task.status()\n",
    "                description = status['description']\n",
    "                state = status['state']\n",
    "                print(f'Task {description} is {state}')\n",
    "            time.sleep(30)\n",
    "    \n",
    "    monitor_tasks([export_flood_task])\n",
    "\n",
    "export_button.on_click(on_export_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CASE 1: Pakistan Floods 2022\n",
    "# inputs\n",
    "# Define the Area of Interest (aoi)\n",
    "\n",
    "name = 'Pakistan_Floods_2022'\n",
    "aoi = ee.Geometry.Polygon(\n",
    "    [[[67.98392410136336, 26.049909335428502],\n",
    "      [67.98392410136336, 25.42892423506662],\n",
    "      [68.59778518534773, 25.42892423506662],\n",
    "      [68.59778518534773, 26.049909335428502]]])\n",
    "\n",
    "startDate = ee.Date('2022-03-01')\n",
    "endDate = ee.Date('2022-08-20')\n",
    "predays = 60\n",
    "postdays = 20\n",
    "\n",
    "# optional\n",
    "split = 0.8\n",
    "zvv_value = -3\n",
    "zvh_val = -3\n",
    "water_value = 75\n",
    "elev_value = 800\n",
    "slope_value = 10\n",
    "num_samples = 200\n",
    "\n",
    "export_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in S1 Pre:  30\n",
      "Images in S1 Post:  11\n",
      "Training Accuracy Metrics:\n",
      "Overall Accuracy: 0.9980891719745223\n",
      "Kappa: 0.9961781578883308\n",
      "Producer's Accuracy: [[0.9974358974358974], [0.9987341772151899]]\n",
      "User's Accuracy: [[0.9987163029525032, 0.9974715549936789]]\n",
      "F1 Score: 0.9981024667931688\n",
      "Validation Accuracy Metrics:\n",
      "Overall Accuracy: 0.7744186046511627\n",
      "Kappa: 0.5492272776396843\n",
      "Producer's Accuracy: [[0.75], [0.8]]\n",
      "User's Accuracy: [[0.7971014492753623, 0.7533632286995515]]\n",
      "F1 Score: 0.7759815242494227\n"
     ]
    }
   ],
   "source": [
    "def get_s1_col(date, days, aoi):\n",
    "    \"\"\"\n",
    "    Fetch Sentinel-1 Image Collection based on the given date and filters.\n",
    "\n",
    "    Parameters:\n",
    "    date (ee.Date): The starting date for filtering the images.\n",
    "    days (int): Number of days for filtering the images.\n",
    "    aoi (ee.Geometry): Area of Interest for filtering the images.\n",
    "\n",
    "    Returns:\n",
    "    ee.ImageCollection: Filtered Sentinel-1 Image Collection.\n",
    "    \"\"\"\n",
    "    filters = [\n",
    "        ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VV\"),\n",
    "        ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VH\"),\n",
    "        ee.Filter.Or(ee.Filter.equals(\"instrumentMode\", \"IW\"), ee.Filter.equals(\"instrumentMode\", \"SM\")),\n",
    "        ee.Filter.bounds(aoi),\n",
    "        ee.Filter.eq('resolution_meters', 10),\n",
    "        ee.Filter.date(date, date.advance(days + 1, 'day'))\n",
    "    ]\n",
    "    \n",
    "    s1_col = ee.ImageCollection('COPERNICUS/S1_GRD').filter(filters)\n",
    "    return s1_col\n",
    "\n",
    "# Fetching pre and post-flood images\n",
    "s1_pre = get_s1_col(startDate, predays, aoi).select(['VV', 'VH'])\n",
    "s1_post = get_s1_col(endDate, postdays, aoi).select(['VV', 'VH'])\n",
    "\n",
    "print('Images in S1 Pre: ', s1_pre.size().getInfo())\n",
    "print('Images in S1 Post: ', s1_post.size().getInfo())\n",
    "\n",
    "asc = ee.Filter.eq(\"orbitProperties_pass\", \"ASCENDING\")\n",
    "des = ee.Filter.eq(\"orbitProperties_pass\", \"DESCENDING\")\n",
    "\n",
    "def calc_zscore(s1_pre, s1_post, direction):\n",
    "    \"\"\"\n",
    "    Calculate Z-score for the given direction (ascending/descending).\n",
    "\n",
    "    Parameters:\n",
    "    s1_pre (ee.ImageCollection): Pre-flood image collection.\n",
    "    s1_post (ee.ImageCollection): Post-flood image collection.\n",
    "    direction (str): Orbit direction (ASCENDING or DESCENDING).\n",
    "\n",
    "    Returns:\n",
    "    ee.Image: Z-score image.\n",
    "    \"\"\"\n",
    "    base_mean = s1_pre.filter(ee.Filter.equals('orbitProperties_pass', direction)).mean()\n",
    "    anom = s1_post.filter(ee.Filter.equals('orbitProperties_pass', direction)).mean().subtract(base_mean)\n",
    "    base_sd = s1_pre.filter(ee.Filter.equals('orbitProperties_pass', direction)).reduce(ee.Reducer.stdDev()).rename(['VV', 'VH'])\n",
    "    return anom.divide(base_sd).set({'system:time_start': s1_post.get('system:time_start')})\n",
    "\n",
    "def zscore_combined():\n",
    "    \"\"\"\n",
    "    Calculate combined Z-score for both ascending and descending orbits.\n",
    "\n",
    "    Returns:\n",
    "    ee.Image: Combined Z-score image.\n",
    "    \"\"\"\n",
    "    zscore_des = calc_zscore(s1_pre, s1_post, 'DESCENDING')\n",
    "    zscore_asc = calc_zscore(s1_pre, s1_post, 'ASCENDING')\n",
    "    zscore = ee.ImageCollection.fromImages([zscore_des, zscore_asc]).mean().clip(aoi)\n",
    "    return zscore\n",
    "\n",
    "def zscore_cond():\n",
    "    \"\"\"\n",
    "    Calculate Z-score based on available orbits (ascending/descending).\n",
    "\n",
    "    Returns:\n",
    "    ee.Image: Z-score image based on available orbits.\n",
    "    \"\"\"\n",
    "    cond_asc = s1_pre.filter(asc).size().gt(0).And(s1_post.filter(asc).size().gt(0))\n",
    "    cond_des = s1_pre.filter(des).size().gt(0).And(s1_post.filter(des).size().gt(0))\n",
    "    \n",
    "    if cond_asc.getInfo():\n",
    "        return calc_zscore(s1_pre, s1_post, 'ASCENDING')\n",
    "    elif cond_des.getInfo():\n",
    "        return calc_zscore(s1_pre, s1_post, 'DESCENDING')\n",
    "    else:\n",
    "        return ee.Image(0)\n",
    "\n",
    "def mapFloods(z, aoi, zvv_thd=-2, zvh_thd=-2, pow_thd=75, elev_thd=800, slp_thd=10):\n",
    "    \"\"\"\n",
    "    Generate flood mask based on Z-score and various thresholds.\n",
    "\n",
    "    Parameters:\n",
    "    z (ee.Image): Z-score image.\n",
    "    aoi (ee.Geometry): Area of Interest.\n",
    "    zvv_thd (float): Threshold for VV band Z-score.\n",
    "    zvh_thd (float): Threshold for VH band Z-score.\n",
    "    pow_thd (float): Threshold for open water percentage.\n",
    "    elev_thd (float): Elevation threshold.\n",
    "    slp_thd (float): Slope threshold.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Flood class and flood layer images.\n",
    "    \"\"\"\n",
    "    # JRC water mask\n",
    "    jrc = ee.ImageCollection(\"JRC/GSW1_4/MonthlyHistory\").filterDate('2016-01-01', '2022-01-01')\n",
    "    jrcvalid = jrc.map(lambda x: x.gt(0)).sum()\n",
    "    jrcwat = jrc.map(lambda x: x.eq(2)).sum().divide(jrcvalid).multiply(100)\n",
    "    jrcmask = jrcvalid.gt(0)\n",
    "    ow = jrcwat.gte(ee.Image(pow_thd))\n",
    "\n",
    "    # Elevation and slope masking using FABDEM\n",
    "    elevation = ee.ImageCollection(\"projects/sat-io/open-datasets/FABDEM\").mosaic().setDefaultProjection('EPSG:3857', None, 30)\n",
    "    slope = ee.Terrain.slope(elevation)\n",
    "\n",
    "    # Classify floods\n",
    "    vvflag = z.select('VV').lte(ee.Image(zvv_thd))\n",
    "    vhflag = z.select('VH').lte(ee.Image(zvh_thd))\n",
    "    flood_class = ee.Image(0).add(vvflag).add(vhflag.multiply(2)).where(ow.eq(1), 4).rename('flood_class')\n",
    "    flood_class = flood_class.where(elevation.gt(elev_thd).multiply(ow.neq(1)), 0).where(slope.gt(slp_thd).multiply(ow.neq(1)), 0)\n",
    "\n",
    "    # Combine flood classes into a single layer\n",
    "    flood_layer = flood_class.where(flood_class.eq(1), 1).where(flood_class.eq(2), 1).where(flood_class.eq(3), 1).where(flood_class.eq(4), 2)\n",
    "    flood_layer = flood_layer.where(jrcmask.eq(0), 2).where(flood_class.eq(0), 2).selfMask().rename('label')\n",
    "    return flood_class.clip(aoi), flood_layer.clip(aoi)\n",
    "\n",
    "# Determine which Z-score calculation to use\n",
    "pre_has_asc = s1_pre.filter(asc).size().gt(0)\n",
    "pre_has_des = s1_pre.filter(des).size().gt(0)\n",
    "post_has_asc = s1_post.filter(asc).size().gt(0)\n",
    "post_has_des = s1_post.filter(des).size().gt(0)\n",
    "cond = pre_has_asc.And(pre_has_des).And(post_has_asc).And(post_has_des)\n",
    "\n",
    "if cond.getInfo():\n",
    "    zscore = zscore_combined()\n",
    "else:\n",
    "    zscore = zscore_cond()\n",
    "\n",
    "# Generate flood masks\n",
    "flood_class, flood_layer = mapFloods(zscore, aoi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------- ******************  -----------------------\n",
    "\n",
    "# Datasets\n",
    "dem_proj = ee.ImageCollection(\"projects/sat-io/open-datasets/FABDEM\")\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .mosaic()\\\n",
    "        .clip(aoi)\\\n",
    "        .setDefaultProjection('EPSG:3857', None, 30)\n",
    "\n",
    "slope_proj = ee.Terrain.slope(dem_proj)\n",
    "aspect = ee.Terrain.aspect(dem_proj)\n",
    "\n",
    "\n",
    "dem = dem_proj.reproject(crs='EPSG:4326', scale=30)\n",
    "slope = slope_proj.reproject(crs='EPSG:4326', scale=30)\n",
    "aspect = aspect.reproject(crs='EPSG:4326', scale=30)\n",
    "\n",
    "\n",
    "# Create the 'sample' feature collection\n",
    "sample = flood_layer.stratifiedSample(\n",
    "    numPoints=num_samples,\n",
    "    classBand='label',\n",
    "    region=aoi,\n",
    "    scale=20,\n",
    "    seed=5,\n",
    "    tileScale=1.5,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "# Update label values: change non-flood (label 2) to 0\n",
    "def updateFeature(feature):\n",
    "    value = feature.get('label')\n",
    "    updated_value = ee.Algorithms.If(ee.Algorithms.IsEqual(value, ee.Number(2)), ee.Number(0), value)\n",
    "    return feature.set('label', updated_value)\n",
    "\n",
    "label = sample.map(updateFeature)\n",
    "\n",
    "# Prepare image for classification\n",
    "image = s1_post.mean().clip(aoi).toFloat()\n",
    "image = image.addBands(dem).addBands(slope).addBands(aspect)\n",
    "\n",
    "flood_layer_bands = image.bandNames().getInfo()\n",
    "\n",
    "# Create training and validation samples\n",
    "sample_all = image.select(flood_layer_bands).sampleRegions(\n",
    "    collection=label,\n",
    "    properties=['label'],\n",
    "    scale=20\n",
    ").randomColumn()\n",
    "\n",
    "training = sample_all.filter(ee.Filter.lt('random', split))\n",
    "validation = sample_all.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "# Train the classifier\n",
    "classifier = ee.Classifier.smileRandomForest(115).train(\n",
    "    features=training,\n",
    "    classProperty='label',\n",
    "    inputProperties=flood_layer_bands\n",
    ")\n",
    "\n",
    "# Classify the image\n",
    "flood_mapped = image.select(flood_layer_bands).classify(classifier)\n",
    "flood_binary = flood_mapped.gt(0).selfMask().rename('flooded')\n",
    "\n",
    "# Accuracy assessment\n",
    "train_accuracy = training.classify(classifier).errorMatrix('label', 'classification')\n",
    "validation_accuracy = validation.classify(classifier).errorMatrix('label', 'classification')\n",
    "\n",
    "def print_am(error_matrix, dataset_name):\n",
    "    \"\"\"\n",
    "    Print accuracy metrics for a given error matrix.\n",
    "\n",
    "    Parameters:\n",
    "    error_matrix (ee.ConfusionMatrix): Error matrix to evaluate.\n",
    "    dataset_name (str): Name of the dataset (e.g., 'Training', 'Validation').\n",
    "    \"\"\"\n",
    "    overall_accuracy = error_matrix.accuracy().getInfo()\n",
    "    kappa = error_matrix.kappa().getInfo()\n",
    "    producers_accuracy = error_matrix.producersAccuracy().getInfo()\n",
    "    consumers_accuracy = error_matrix.consumersAccuracy().getInfo()\n",
    "    f1_score = error_matrix.fscore().getInfo()[1]  # F1 score for the flood class (1)\n",
    "\n",
    "    print(f\"{dataset_name} Accuracy Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy}\")\n",
    "    print(f\"Kappa: {kappa}\")\n",
    "    print(f\"Producer's Accuracy: {producers_accuracy}\")\n",
    "    print(f\"User's Accuracy: {consumers_accuracy}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "print_am(train_accuracy, \"Training\")\n",
    "print_am(validation_accuracy, \"Validation\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize flood_class and flood_layer\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi, 10)\n",
    "Map.addLayer(flood_class, {'min': 0, 'max': 4, 'palette': ['white', 'blue', 'yellow', 'red', 'green']}, 'Flood Class')\n",
    "Map.addLayer(flood_layer, {'min': 0, 'max': 2, 'palette': ['white', 'red', 'green']}, 'Flood Layer')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code to compare models\n",
    "\n",
    "# Parameters\n",
    "num_samples = 1000  # Number of sample points\n",
    "split = 0.8  # Train-test split ratio\n",
    "bands = ['VV', 'VH']  # Bands to use for classification\n",
    "\n",
    "# Create the 'sample' feature collection\n",
    "sample = flood_layer.stratifiedSample(\n",
    "    numPoints=num_samples,\n",
    "    classBand='label',\n",
    "    region=aoi,\n",
    "    scale=10,\n",
    "    seed=5,\n",
    "    tileScale=1.5,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "# Update label values: change non-flood (label 2) to 0\n",
    "def updateFeature(feature):\n",
    "    value = feature.get('label')\n",
    "    updated_value = ee.Algorithms.If(ee.Algorithms.IsEqual(value, ee.Number(2)), ee.Number(0), value)\n",
    "    return feature.set('label', updated_value)\n",
    "\n",
    "label = sample.map(updateFeature)\n",
    "\n",
    "# Verify label values\n",
    "unique_labels = label.aggregate_array('label').distinct().getInfo()\n",
    "print(f\"Unique labels: {unique_labels}\")\n",
    "\n",
    "# Prepare image for classification\n",
    "image = s1_post.mean().clip(aoi)\n",
    "\n",
    "# Create training and validation samples\n",
    "sample_all = image.select(bands).sampleRegions(\n",
    "    collection=label,\n",
    "    properties=['label'],\n",
    "    scale=10\n",
    ").randomColumn()\n",
    "\n",
    "training = sample_all.filter(ee.Filter.lt('random', split))\n",
    "validation = sample_all.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "# Define classifiers to compare\n",
    "classifiers = {\n",
    "    'RandomForest': ee.Classifier.smileRandomForest(115),\n",
    "    'GradientTreeBoost': ee.Classifier.smileGradientTreeBoost(100),\n",
    "    'DecisionTree': ee.Classifier.smileCart(),\n",
    "    #'NaiveBayes': ee.Classifier.smileNaiveBayes(),\n",
    "    'SVM': ee.Classifier.libsvm()\n",
    "}\n",
    "\n",
    "def evaluate_classifier(classifier, training, validation):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    trained_classifier = classifier.train(\n",
    "        features=training,\n",
    "        classProperty='label',\n",
    "        inputProperties=bands\n",
    "    )\n",
    "    \n",
    "    training_classified = training.classify(trained_classifier)\n",
    "    validation_classified = validation.classify(trained_classifier)\n",
    "    \n",
    "    training_accuracy = training_classified.errorMatrix('label', 'classification')\n",
    "    validation_accuracy = validation_classified.errorMatrix('label', 'classification')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    prediction_time = end_time - start_time\n",
    "    \n",
    "    return {\n",
    "        'train_f1': training_accuracy.fscore().getInfo()[1] if len(training_accuracy.fscore().getInfo()) > 1 else None,\n",
    "        'validation_f1': validation_accuracy.fscore().getInfo()[1] if len(validation_accuracy.fscore().getInfo()) > 1 else None,\n",
    "        'train_producer_accuracy': training_accuracy.producersAccuracy().getInfo()[1] if len(training_accuracy.producersAccuracy().getInfo()) > 1 else None,\n",
    "        'validation_producer_accuracy': validation_accuracy.producersAccuracy().getInfo()[1] if len(validation_accuracy.producersAccuracy().getInfo()) > 1 else None,\n",
    "        'train_consumer_accuracy': training_accuracy.consumersAccuracy().getInfo()[1] if len(training_accuracy.consumersAccuracy().getInfo()) > 1 else None,\n",
    "        'validation_consumer_accuracy': validation_accuracy.consumersAccuracy().getInfo()[1] if len(validation_accuracy.consumersAccuracy().getInfo()) > 1 else None,\n",
    "        'prediction_time': prediction_time\n",
    "    }\n",
    "\n",
    "# Evaluate all classifiers\n",
    "results = {}\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Evaluating {name} classifier...\")\n",
    "    results[name] = evaluate_classifier(classifier, training, validation)\n",
    "\n",
    "# Print results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\nClassifier: {name}\")\n",
    "    print(f\"Training F1 Score: {metrics['train_f1']}\")\n",
    "    print(f\"Validation F1 Score: {metrics['validation_f1']}\")\n",
    "    print(f\"Training Producer Accuracy: {metrics['train_producer_accuracy']}\")\n",
    "    print(f\"Validation Producer Accuracy: {metrics['validation_producer_accuracy']}\")\n",
    "    print(f\"Training Consumer Accuracy: {metrics['train_consumer_accuracy']}\")\n",
    "    print(f\"Validation Consumer Accuracy: {metrics['validation_consumer_accuracy']}\")\n",
    "    print(f\"Prediction Time: {metrics['prediction_time']} seconds\")\n",
    "\n",
    "# Optionally, export the best classifier's results\n",
    "# best_classifier_name = max(results, key=lambda k: results[k]['validation_f1'])\n",
    "# best_classifier = classifiers[best_classifier_name].train(\n",
    "#     features=training,\n",
    "#     classProperty='label',\n",
    "#     inputProperties=bands\n",
    "# )\n",
    "# classified_image = image.select(bands).classify(best_classifier)\n",
    "# geemap.ee_export_image_to_drive(classified_image, description=f'best_classifier_{best_classifier_name}', folder='earth_engine', scale=10, region=aoi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Susceptibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables Preparation for Susceptibility\n",
    "# Variables used: DEM, Slope, Aspect, NDVI, NDWI, NDBI, NDSI\n",
    "\n",
    "# Apply scaling factors to Landsat images\n",
    "def applyScaleFactors(image):\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "    return image.addBands(opticalBands, None, True).addBands(thermalBands, None, True)\n",
    "\n",
    "# Year extraction from endDate\n",
    "year = ee.Date(endDate).get('year')\n",
    "\n",
    "# Filter Landsat 8 for 2013 to end of 2021\n",
    "l8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .filterDate('2013-01-01', '2021-11-01')\n",
    "\n",
    "# Filter Landsat 9 for 2022 onwards\n",
    "l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\\\n",
    "        .filterBounds(aoi)\n",
    "\n",
    "# Combine both collections, prioritizing Landsat 9 for 2022\n",
    "landsat_combined = l8.merge(l9)\n",
    "\n",
    "# Filter the combined collection for the specified year\n",
    "landsat_filtered = landsat_combined.filter(ee.Filter.calendarRange(year, year, 'year'))\\\n",
    "                                   .filter(ee.Filter.lt('CLOUD_COVER', 10))\\\n",
    "                                   .map(applyScaleFactors)\\\n",
    "                                   .median()\\\n",
    "                                   .clip(aoi)\n",
    "proj = landsat_filtered.projection()\n",
    "# Datasets\n",
    "dem = ee.ImageCollection(\"projects/sat-io/open-datasets/FABDEM\")\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .mosaic()\\\n",
    "        .clip(aoi).reproject('EPSG:3395', None, 30).rename('elevation')\n",
    "\n",
    "dem_proj = dem.setDefaultProjection(proj)\n",
    "\n",
    "slope = ee.Terrain.slope(dem)\n",
    "aspect = ee.Terrain.aspect(dem)\n",
    "\n",
    "\n",
    "slope_proj = slope.setDefaultProjection(proj)\n",
    "aspect_proj = aspect.setDefaultProjection(proj)\n",
    "\n",
    "\n",
    "ndvi = landsat_filtered.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')\n",
    "ndwi = landsat_filtered.normalizedDifference(['SR_B3', 'SR_B5']).rename('NDWI')\n",
    "ndbi = landsat_filtered.normalizedDifference(['SR_B6', 'SR_B5']).rename('NDBI')\n",
    "ndsi = landsat_filtered.normalizedDifference(['SR_B2', 'SR_B5']).rename('NDSI')\n",
    "\n",
    "landsat_filtered = landsat_filtered.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n",
    "\n",
    "rainfall = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\\\n",
    "            .filterDate('2018-01-01', '2023-01-01')\\\n",
    "            .filterBounds(aoi)\\\n",
    "            .map(lambda image: image.gt(10).selfMask())\\\n",
    "            .map(lambda image: image.clip(aoi))\\\n",
    "            .sum().rename('rainfall')\\\n",
    "            #.reproject(proj.crs(), None, 30)\n",
    "\n",
    "# Combine all layers into one image\n",
    "image_sus = landsat_filtered.addBands(ndvi).addBands(ndwi).addBands(ndbi).addBands(ndsi)\\\n",
    "                            .addBands(dem_proj).addBands(slope_proj).addBands(aspect_proj)\\\n",
    "                            .addBands(rainfall)\\\n",
    "                            .clip(aoi)\n",
    "\n",
    "# Get band names\n",
    "bands_sus = image_sus.bandNames().getInfo()\n",
    "\n",
    "# Create the flood labels based on ML classified flood layer\n",
    "\n",
    "sample_new = flood_mapped.rename('label').stratifiedSample(\n",
    "    numPoints=num_samples,\n",
    "    classBand='label',\n",
    "    region=aoi,\n",
    "    scale=30,\n",
    "    seed=5,\n",
    "    tileScale=1.5,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "# Update label values: change non-flood (label 2) to 0\n",
    "def updateFeature(feature):\n",
    "    value = feature.get('label')\n",
    "    updated_value = ee.Algorithms.If(ee.Algorithms.IsEqual(value, ee.Number(2)), ee.Number(0), value)\n",
    "    return feature.set('label', updated_value)\n",
    "\n",
    "label_new = sample_new.map(updateFeature)\n",
    "\n",
    "\n",
    "# Training sample collection\n",
    "sample_all_sus = image_sus.select(bands_sus).clip(aoi).sampleRegions(\n",
    "    collection=label_new,\n",
    "    properties=['label'],\n",
    "    scale=30,\n",
    "    tileScale=1.5\n",
    ").randomColumn()\n",
    "\n",
    "# size of sample_all_sus\n",
    "print('Size of sample_all_sus: ', sample_all_sus.size().getInfo())\n",
    "\n",
    "\n",
    "training_sus = sample_all_sus.filter(ee.Filter.lt('random', split))\n",
    "validation_sus = sample_all_sus.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "# Train the classifier\n",
    "classifier_sus = ee.Classifier.smileRandomForest(115).train(\n",
    "    features=training_sus,\n",
    "    classProperty='label',\n",
    "    inputProperties=bands_sus\n",
    ")\n",
    "\n",
    "# Set the classifier to output probabilities\n",
    "classifier_prob = classifier_sus.setOutputMode('PROBABILITY')\n",
    "\n",
    "# Classify the image to get flood susceptibility probabilities\n",
    "flood_prob = image_sus.classify(classifier_prob)\n",
    "\n",
    "# Accuracy assessment\n",
    "def calculate_metrics(validation, classifier):\n",
    "    validation_classified = validation.classify(classifier)\n",
    "    validation_accuracy = validation_classified.errorMatrix('label', 'classification')\n",
    "    \n",
    "    f1_score = validation_accuracy.fscore().getInfo()[1] if len(validation_accuracy.fscore().getInfo()) > 1 else None\n",
    "    producer_accuracy = validation_accuracy.producersAccuracy().getInfo()[1] if len(validation_accuracy.producersAccuracy().getInfo()) > 1 else None\n",
    "    consumer_accuracy = validation_accuracy.consumersAccuracy().getInfo()[1] if len(validation_accuracy.consumersAccuracy().getInfo()) > 1 else None\n",
    "    \n",
    "    return f1_score, producer_accuracy, consumer_accuracy\n",
    "\n",
    "f1_score, producer_accuracy, consumer_accuracy = calculate_metrics(validation_sus, classifier_sus)\n",
    "\n",
    "print(\"Validation F1 Score:\", f1_score)\n",
    "print(\"Validation Producer Accuracy:\", producer_accuracy)\n",
    "print(\"Validation Consumer Accuracy:\", consumer_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of label collection: 2000\n",
      "Image Projection Information:\n",
      "{'type': 'Projection', 'crs': 'EPSG:4326', 'transform': [1, 0, 0, 0, 1, 0]}\n",
      "\n",
      "Feature Collection Projection Information:\n",
      "{'type': 'Projection', 'crs': 'EPSG:4326', 'transform': [1, 0, 0, 0, 1, 0]}\n",
      "Size of sample_all_sus: 1992\n",
      "Training set size: 1604\n",
      "Validation set size: 388\n",
      "Validation F1 Score: 0.7154046997389033\n",
      "Validation Producer Accuracy: [0.7210526315789474]\n",
      "Validation Consumer Accuracy: None\n"
     ]
    }
   ],
   "source": [
    "# Main susceptibility code\n",
    "\n",
    "# Apply scaling factors to Landsat images\n",
    "def applyScaleFactors(image):\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "    return image.addBands(opticalBands, None, True).addBands(thermalBands, None, True)\n",
    "\n",
    "# Year extraction from endDate\n",
    "year = ee.Date(endDate).get('year')\n",
    "\n",
    "# Filter Landsat 8 for 2013 to end of 2021\n",
    "l8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .filterDate('2013-01-01', '2021-12-31')\n",
    "\n",
    "# Filter Landsat 9 for 2022 onwards\n",
    "l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .filterDate('2022-01-01', endDate)\n",
    "\n",
    "\n",
    "# Combine both collections, prioritizing Landsat 9 for 2022\n",
    "landsat_combined = l8.merge(l9)\n",
    "\n",
    "# Filter the combined collection for the specified year\n",
    "landsat_filtered = landsat_combined.filter(ee.Filter.calendarRange(year, year, 'year'))\\\n",
    "                                   .filter(ee.Filter.lt('CLOUD_COVER', 40))\\\n",
    "                                   .filterBounds(aoi)\\\n",
    "                                   .map(applyScaleFactors)\\\n",
    "                                   .median()\\\n",
    "                                   .clip(aoi)\n",
    "\n",
    "\n",
    "ndvi = landsat_filtered.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')#.reproject('EPSG:3395', None, 30)\n",
    "ndwi = landsat_filtered.normalizedDifference(['SR_B3', 'SR_B5']).rename('NDWI')#.reproject('EPSG:3395', None, 30)\n",
    "ndbi = landsat_filtered.normalizedDifference(['SR_B6', 'SR_B5']).rename('NDBI')#.reproject('EPSG:3395', None, 30)\n",
    "ndsi = landsat_filtered.normalizedDifference(['SR_B2', 'SR_B5']).rename('NDSI')#.reproject('EPSG:3395', None, 30)\n",
    "\n",
    "rainfall = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\\\n",
    "            .filterDate('2018-01-01', '2023-01-01')\\\n",
    "            .filterBounds(aoi)\\\n",
    "            .map(lambda image: image.gt(10).selfMask())\\\n",
    "            .map(lambda image: image.clip(aoi))\\\n",
    "            .sum().rename('rainfall')\\\n",
    "            .reproject(crs='EPSG:4326')\n",
    "\n",
    "landsat_filtered = landsat_filtered.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\\\n",
    "                        .addBands(ndvi).addBands(ndwi).addBands(ndbi).addBands(ndsi)\\\n",
    "\n",
    "# Combine all layers into one image\n",
    "image_sus = landsat_filtered.addBands(dem).addBands(slope).addBands(aspect)\\\n",
    "                            .addBands(rainfall)\\\n",
    "                            .clip(aoi).setDefaultProjection('EPSG:4326')\n",
    "\n",
    "# Get band names\n",
    "bands_sus = image_sus.bandNames().getInfo()\n",
    "\n",
    "# Reproject labels to EPSG:3395\n",
    "#label = ee.FeatureCollection(label).map(lambda feature: feature.setGeometry(feature.geometry().transform('EPSG:3395')))\n",
    "\n",
    "# Check if the label collection has valid data\n",
    "label_size = label.size().getInfo()\n",
    "print('Size of label collection:', label_size)\n",
    "\n",
    "# Check projections\n",
    "image_proj = image_sus.projection().getInfo()\n",
    "feature_proj = label.first().geometry().projection().getInfo()\n",
    "print(\"Image Projection Information:\")\n",
    "print(image_proj)\n",
    "print(\"\\nFeature Collection Projection Information:\")\n",
    "print(feature_proj)\n",
    "\n",
    "# Training sample collection\n",
    "sample_all_sus = image_sus.select(bands_sus).sampleRegions(\n",
    "    collection=label,\n",
    "    properties=['label'],\n",
    "    scale=30,\n",
    "    tileScale=2\n",
    ")\n",
    "\n",
    "# Print size of sample_all_sus\n",
    "sample_size = sample_all_sus.size().getInfo()\n",
    "print('Size of sample_all_sus:', sample_size)\n",
    "\n",
    "if sample_size == 0:\n",
    "    # Debug information if no samples are found\n",
    "    print('No samples found. Check the intersection of the label and image_sus.')\n",
    "    \n",
    "    # Get the bounding box of the aoi and label geometries\n",
    "    aoi_bbox = aoi.bounds().getInfo()\n",
    "    label_bbox = label.geometry().bounds().getInfo()\n",
    "    print(\"AOI Bounding Box:\", aoi_bbox)\n",
    "    print(\"Label Bounding Box:\", label_bbox)\n",
    "\n",
    "# Continue with the random column and rest of the code only if samples are found\n",
    "if sample_size > 0:\n",
    "    sample_all_sus = sample_all_sus.randomColumn()\n",
    "\n",
    "    training_sus = sample_all_sus.filter(ee.Filter.lt('random', split))\n",
    "    validation_sus = sample_all_sus.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "    # Print sizes of training and validation sets\n",
    "    training_size = training_sus.size().getInfo()\n",
    "    validation_size = validation_sus.size().getInfo()\n",
    "    print(f\"Training set size: {training_size}\")\n",
    "    print(f\"Validation set size: {validation_size}\")\n",
    "\n",
    "    # Ensure there are valid training and validation samples\n",
    "    if training_size == 0 or validation_size == 0:\n",
    "        raise ValueError(\"No valid training or validation samples found. Check the sampling and filtering steps.\")\n",
    "\n",
    "    # Train the classifier\n",
    "    classifier_sus = ee.Classifier.smileRandomForest(115).train(\n",
    "        features=training_sus,\n",
    "        classProperty='label',\n",
    "        inputProperties=bands_sus\n",
    "    )\n",
    "\n",
    "    # Set the classifier to output probabilities\n",
    "    classifier_prob = classifier_sus.setOutputMode('PROBABILITY')\n",
    "\n",
    "    # Classify the image to get flood susceptibility probabilities\n",
    "    flood_prob = image_sus.classify(classifier_prob)\n",
    "\n",
    "    # Accuracy assessment\n",
    "    def calculate_metrics(validation, classifier):\n",
    "        validation_classified = validation.classify(classifier)\n",
    "        validation_accuracy = validation_classified.errorMatrix('label', 'classification')\n",
    "\n",
    "        f1_score = validation_accuracy.fscore().getInfo()[1] if len(validation_accuracy.fscore().getInfo()) > 1 else None\n",
    "        producer_accuracy = validation_accuracy.producersAccuracy().getInfo()[1] if len(validation_accuracy.producersAccuracy().getInfo()) > 1 else None\n",
    "        consumer_accuracy = validation_accuracy.consumersAccuracy().getInfo()[1] if len(validation_accuracy.consumersAccuracy().getInfo()) > 1 else None\n",
    "\n",
    "        return f1_score, producer_accuracy, consumer_accuracy\n",
    "\n",
    "    f1_score, producer_accuracy, consumer_accuracy = calculate_metrics(validation_sus, classifier_sus)\n",
    "\n",
    "    print(\"Validation F1 Score:\", f1_score)\n",
    "    print(\"Validation Producer Accuracy:\", producer_accuracy)\n",
    "    print(\"Validation Consumer Accuracy:\", consumer_accuracy)\n",
    "else:\n",
    "    print(\"No samples found. Please check the data and ensure the label and image_sus intersect spatially and temporally.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Projection', 'crs': 'EPSG:4326', 'transform': [1, 0, 0, 0, 1, 0]}\n",
      "{'type': 'Projection', 'crs': 'EPSG:4326', 'transform': [1, 0, 0, 0, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "# projectio of the image\n",
    "print(flood_mapped.projection().getInfo())\n",
    "print(flood_prob.projection().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbeeb163fa6426eb23851abb370235a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[25.73946796510279, 68.29085464335516], controls=(WidgetControl(options=['position', 'transparent_bâ€¦"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize flood layer and flood susceptibility probabilities\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi, 10)\n",
    "Map.addLayer(flood_mapped, {'min': 0, 'max': 1, 'palette': ['grey', 'red']}, 'Flood Layer')\n",
    "Map.addLayer(flood_prob, {'min': 0, 'max': 1, 'palette': ['#006837', ' #3ba858', ' #9dd569', ' #e4f49a', ' #fee99a', ' #fca55d', ' #e34a33', ' #a50026']}, 'Flood Susceptibility Probabilities')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task flood_layer is READY\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m30\u001b[39m)  \u001b[38;5;66;03m# Check every 15 seconds\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Monitor the export tasks\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mmonitor_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mflood_layer_task\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m, in \u001b[0;36mmonitor_tasks\u001b[0;34m(tasks)\u001b[0m\n\u001b[1;32m     31\u001b[0m     state \u001b[38;5;241m=\u001b[39m status[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "export_data = True\n",
    "if export_data==True:\n",
    "    # Export the classified image\n",
    "    flood_layer_task = ee.batch.Export.image.toDrive(\n",
    "        image=flood_binary,\n",
    "        description='flood_layer',\n",
    "        folder='earth_engine_exports',\n",
    "        scale=10,\n",
    "        region=aoi,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    flood_layer_task.start()\n",
    "    # Export susceptibility layer\n",
    "    susceptibility_task = ee.batch.Export.image.toDrive(\n",
    "        image=flood_prob,\n",
    "        description='flood_susceptibility_layer',\n",
    "        folder='earth_engine_exports',\n",
    "        scale=30,\n",
    "        region=aoi,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "\n",
    "    susceptibility_task.start()\n",
    "\n",
    "    # Function to monitor the progress of the export tasks\n",
    "    def monitor_tasks(tasks):\n",
    "        while any([task.status()['state'] in ['READY', 'RUNNING'] for task in tasks]):\n",
    "            for task in tasks:\n",
    "                status = task.status()\n",
    "                description = status['description']\n",
    "                state = status['state']\n",
    "                print(f'Task {description} is {state}')\n",
    "            time.sleep(30)  # Check every 15 seconds\n",
    "\n",
    "    # Monitor the export tasks\n",
    "    monitor_tasks([flood_layer_task, susceptibility_task])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1/projects/earthengine-legacy/thumbnails/158ac91a7174277528fe3aece291df45-c421b52d853560a079af683c6178b8b0:getPixels\n",
      "Please wait ...\n",
      "An error occurred while downloading.\n"
     ]
    }
   ],
   "source": [
    "# scale image between 1 to 100 (integers) and export\n",
    "results_prob_scaled = results_prob.multiply(100).toInt()\n",
    "geemap.ee_export_image(results_prob_scaled, filename='flood_susceptibility.tif', scale=30, region=aoi, file_per_band=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_sus = sample_all_sus.filter(ee.Filter.lt('random', split))\n",
    "validation_sus = sample_all_sus.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "# Train the classifier\n",
    "classifier_sus = ee.Classifier.smileRandomForest(115).train(\n",
    "    features=training_sus,\n",
    "    classProperty='label',\n",
    "    inputProperties=bands_sus\n",
    ")\n",
    "\n",
    "# Set the classifier to output probabilities\n",
    "classifier_prob = classifier_sus.setOutputMode('PROBABILITY')\n",
    "\n",
    "# Classify the image to get flood susceptibility probabilities\n",
    "results_prob = image_sus.classify(classifier_prob)\n",
    "\n",
    "# Accuracy assessment\n",
    "def calculate_metrics(validation, classifier):\n",
    "    validation_classified = validation.classify(classifier)\n",
    "    validation_accuracy = validation_classified.errorMatrix('label', 'classification')\n",
    "    \n",
    "    f1_score = validation_accuracy.fscore().getInfo()[1] if len(validation_accuracy.fscore().getInfo()) > 1 else None\n",
    "    producer_accuracy = validation_accuracy.producersAccuracy().getInfo()[1] if len(validation_accuracy.producersAccuracy().getInfo()) > 1 else None\n",
    "    consumer_accuracy = validation_accuracy.consumersAccuracy().getInfo()[1] if len(validation_accuracy.consumersAccuracy().getInfo()) > 1 else None\n",
    "    \n",
    "    return f1_score, producer_accuracy, consumer_accuracy\n",
    "\n",
    "f1_score, producer_accuracy, consumer_accuracy = calculate_metrics(validation_sus, classifier_sus)\n",
    "\n",
    "print(\"Validation F1 Score:\", f1_score)\n",
    "print(\"Validation Producer Accuracy:\", producer_accuracy)\n",
    "print(\"Validation Consumer Accuracy:\", consumer_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results on the map\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi, 10)\n",
    "Map.addLayer(results_prob, {'min': 0, 'max': 1, 'palette': ['green', 'blue', 'red']}, 'Flood Susceptibility')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables Preperation for Susceptibility\n",
    "\n",
    "\n",
    "# varianles used DEM, Slope, Aspect, NDVI, NDWI, NDBI, NDSI\n",
    "\n",
    "# Applies scaling factors.\n",
    "year = endDate.get('year')\n",
    "def applyScaleFactors(image):\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "    \n",
    "    return image.addBands(opticalBands, None, True)\\\n",
    "              .addBands(thermalBands, None, True)\n",
    "\n",
    "def remapper(image):\n",
    "        remapped = image.remap([1,2,4,5,7,8,9,10,11],[1,2,3,4,5,6,7,8,9])\n",
    "        return remapped\n",
    "\n",
    "# datasets\n",
    "dem = ee.ImageCollection(\"projects/sat-io/open-datasets/FABDEM\")\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .mosaic()\\\n",
    "        .clip(aoi)\n",
    "\n",
    "slope = ee.Terrain.slope(dem)\n",
    "aspect = ee.Terrain.aspect(dem)\n",
    "\n",
    "\n",
    "l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .filter(ee.Filter.calendarRange(year, year, 'year'))\\\n",
    "        .map(applyScaleFactors)\\\n",
    "        .filter(ee.Filter.lt('CLOUD_COVER', 10))\\\n",
    "        .median()\\\n",
    "        .clip(aoi)\n",
    "\n",
    "\n",
    "ndvi = l9.normalizedDifference(['SR_B5', 'SR_B4'])\n",
    "ndwi = l9.normalizedDifference(['SR_B3', 'SR_B5'])\n",
    "ndbi = l9.normalizedDifference(['SR_B6', 'SR_B5'])\n",
    "ndsi = l9.normalizedDifference(['SR_B2', 'SR_B5'])\n",
    "\n",
    "l9 = l9.select(['SR_B1','SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n",
    "\n",
    "image_sus = l9.addBands(dem).addBands(slope).addBands(aspect).addBands(ndvi).addBands(ndwi).addBands(ndbi).addBands(ndsi).clip(aoi)\n",
    "\n",
    "bands_sus = image_sus.bandNames().getInfo()\n",
    "\n",
    "# training\n",
    "sample_all_sus = image_sus.select(bands_sus).sampleRegions(**{\n",
    "    'collection': label,\n",
    "    'properties': ['label'],\n",
    "    'scale': 30\n",
    "})\n",
    "\n",
    "sample_all_sus = sample_all_sus.randomColumn()\n",
    "\n",
    "split = 0.9\n",
    "training_sus = sample_all_sus.filter(ee.Filter.lt('random', split))\n",
    "validation_sus = sample_all_sus.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "\n",
    "classifier_sus = ee.Classifier.smileRandomForest(115).train(**{\n",
    "    'features': training_sus,\n",
    "    'classProperty': 'label',\n",
    "    'inputProperties': bands_sus\n",
    "})\n",
    "\n",
    "classifier_prob = classifier_sus.setOutputMode('PROBABILITY')\n",
    "results_prob = image_sus.select(bands).classify(classifier_prob)\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi, 10)\n",
    "Map.addLayer(results_prob, {'min': 0, 'max': 1, 'palette': ['green', 'blue', 'red']}, 'Flood Susceptibility');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(results, {'min': 1, 'max': 3, 'palette': ['white', 'red', '233CF0']}, 'Flood Classified');\n",
    "Map.addLayer(results_prob, {'min': 0, 'max': 1, 'palette': ['white', 'blue', '233CF0']}, 'Flood Susceptibility');\n",
    "\n",
    "# map\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi)\n",
    "Map.addLayer(aoi, {}, 'Area of Interest')\n",
    "Map.addLayer(zscore.select('VV'), {'min': -7, 'max': 7, 'palette': ['red', 'white', 'blue']}, 'ZScore', False)\n",
    "Map.addLayer(flood_class, {'min': 0, 'max': 4, 'palette': ['#E3E3E3','#FFB100', '#FFB100', '#3E9DFF','#031DC9']}, 'flood classes', False)\n",
    "Map.addLayer(flood_layer, {'min': 1, 'max': 2, 'palette': ['blue', 'white']}, 'flood layer', False)\n",
    "Map.addLayer(label, {}, 'Label')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_explain = classifier.explain()\n",
    "variable_importance = ee.Feature(None, ee.Dictionary(classifier_explain).get('importance'))\n",
    "#print('Classifier Explain: ', classifier_explain)\n",
    "print('Variable Importance: ', variable_importance.getInfo())\n",
    "train_accuracy = classifier.confusionMatrix()\n",
    "print('Train Accuracy', train_accuracy.getInfo())\n",
    "print('Overall Accuracy: ', train_accuracy.accuracy().getInfo())\n",
    "print('Kappa: ', train_accuracy.kappa().getInfo())\n",
    "print('Producer Accuracy: ', train_accuracy.producersAccuracy().getInfo())\n",
    "print('Consumer Accuracy: ', train_accuracy.consumersAccuracy().getInfo())\n",
    "\n",
    "validated = validation.classify(classifier)\n",
    "print('Validation', validated.first().getInfo())\n",
    "test_accuracy = validated.errorMatrix('label', 'classification')\n",
    "print('Validation Accuracy', test_accuracy.getInfo())\n",
    "print('Validation Overall Accuracy: ', test_accuracy.accuracy().getInfo())\n",
    "print('Validation Kappa: ', test_accuracy.kappa().getInfo())\n",
    "print('Validation Producer Accuracy: ', test_accuracy.producersAccuracy().getInfo())\n",
    "print('Validation Consumer Accuracy: ', test_accuracy.consumersAccuracy().getInfo())\n",
    "\n",
    "f1_train = train_accuracy.fscore().getInfo()[1]\n",
    "print('F1 Score Train: ', f1_train)\n",
    "\n",
    "f1_test = test_accuracy.fscore().getInfo()[1]\n",
    "print('F1 Score Test: ', f1_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
